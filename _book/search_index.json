[
["intro.html", "2 What is autocorrelation? 2.1 Simple correlation 2.2 One dimensional autocorrelation 2.3 Two dimensional autocorrelation", " 2 What is autocorrelation? spatial library(tidyverse) 2.1 Simple correlation A variable y is correlated with a variable x and its slope is \\(\\beta_1\\) In likelihood methods, this statement can be written as: \\[ y_i \\sim N(\\beta_0 + \\beta_1 x_i, \\sigma) \\\\ \\] or \\[ y_i = \\beta_0 + \\beta_1 x_i +\\epsilon_i \\\\ \\epsilon_i \\sim N(0, \\sigma) \\] We have three parameters \\(\\beta_0, \\beta_1, \\sigma\\) in this simple linear model. set.seed(1234) N &lt;- 50 beta0 &lt;- 2 beta1 &lt;- 0.8 sigma &lt;- 0.3 x &lt;- rnorm(N, 0, 1) y &lt;- rnorm(N, beta0 + beta1 * x, sigma) dat &lt;- tibble(x, y, n = seq(1, N)) ggplot(dat, aes(x = x , y = y)) + geom_point() dat %&gt;% gather(xy, val, 1:2) %&gt;% ggplot(., aes(x = n , y = val, col = xy)) + geom_point() + geom_line() cor.test(x, y) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: x and y #&gt; t = 15, df = 48, p-value &lt;2e-16 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.849 0.949 #&gt; sample estimates: #&gt; cor #&gt; 0.912 2.2 One dimensional autocorrelation Previous observation(s) affects the current observation. Temporal autocorrelation is this type of the autocorrelation. \\[ x_i = x_{i_1} + \\epsilon_{x} \\\\ y_i = y_{i_1} + \\epsilon_{y} \\\\ \\epsilon_{y} \\sim N(0, \\sigma_y) \\\\ \\epsilon_{x} \\sim N(0, \\sigma_x) \\] set.seed(25) N &lt;- 50 x &lt;- y &lt;- NULL x[1] &lt;- 0 y[1] &lt;- 0 for (i in 1:(N-1)) { y[i + 1] &lt;- rnorm(1, y[i], 0.8) x[i + 1] &lt;- rnorm(1, x[i], 0.8) } y &lt;- cumsum(rnorm(N)) x &lt;- cumsum(rnorm(N)) #acf(y, type = &quot;correlation&quot;) #cor(y[-1], y[-50]) #cor(y[-1:-2], y[-50:-49]) dat &lt;- tibble(x, y, n = seq(1, N)) ggplot(dat, aes(x = x , y = y)) + geom_point() dat %&gt;% gather(xy, val, 1:2) %&gt;% ggplot(., aes(x = n , y = val, col = xy)) + geom_point() + geom_line() cor.test(x, y) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: x and y #&gt; t = -0.02, df = 48, p-value = 1 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; -0.281 0.276 #&gt; sample estimates: #&gt; cor #&gt; -0.00234 We got a strong correlation for the two variables that are supposed to be independent. Each point shows daily measurements Do you believe this? Do you believe this? 2.3 Two dimensional autocorrelation Neighbors affect the current observation. Spatial autocorrelation is this type of the autocorrelation. 2D \\[ Y = X \\beta + \\rho W (Y - X \\beta) + \\epsilon \\] library(spdep) #&gt; Loading required package: sp #&gt; Loading required package: spData #&gt; Warning: multiple methods tables found for &#39;wkt&#39; #&gt; To access larger datasets in this package, install the spDataLarge #&gt; package with: `install.packages(&#39;spDataLarge&#39;, #&gt; repos=&#39;https://nowosad.github.io/drat/&#39;, type=&#39;source&#39;)` #&gt; Loading required package: sf #&gt; Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.2 library(Matrix) #&gt; #&gt; Attaching package: &#39;Matrix&#39; #&gt; The following objects are masked from &#39;package:tidyr&#39;: #&gt; #&gt; expand, pack, unpack set.seed(1234) N &lt;- 50 x &lt;- seq(1, 25) y &lt;- seq(1, 25) nb &lt;- cell2nb(length(x),length(y), type = &quot;queen&quot;) W &lt;- nb2listw(nb, zero.policy = TRUE, style = &quot;W&quot;) B &lt;- nb2mat(nb, zero.policy = TRUE, style = &quot;W&quot;) #z &lt;- matrix(numeric(length(x) * length(y)), ncol = length(y)) z &lt;- matrix(rnorm(length(x) * length(y)), ncol = length(y)) automean2&lt;-function(metric){ #queen?equal weighting 1/8 d.W&lt;-nb2listw(d.nb, zero.policy=TRUE,style=&quot;W&quot;) #SAR a&lt;-spautolm(metric~ 1,listw=d.W,na.action=na.omit) return(a$fit$fitted.values) } z0 &lt;- z z2 &lt;- z for (i in 2:(length(x)-1)) { for (j in 2:(length(y)-1)) { z[i, j] &lt;- rnorm(1, mean( c(z[i - 1, j - 1], z[i - 1, j], z[i - 1, j + 1], z[i, j - 1], z[i, j + 1], z[i + 1, j - 1], z[i + 1, j], z[i + 1, j + 1])), 0) } } z_scaled &lt;- (z - mean(as.numeric(z))) / sd(as.numeric(z)) z2 &lt;- z z2[z &gt; 0] &lt;- &quot;ridge&quot; z2[z &lt; 0] &lt;- &quot;valley&quot; #z2[z &gt; -0.5 &amp; z &lt; 0.5] &lt;- &quot;flat&quot; #z2 &lt;- z2 + z x2 &lt;- rep(x, length(y)) y2 &lt;- rep(y, each = length(x)) dat &lt;- tibble(x = x2, y = y2, mu = as.vector(z), hab = as.vector(z2), z = as.numeric(z_scaled), z0 = as.numeric(z0) ) ggplot(dat, aes(x = x, y = y, fill = z0)) + geom_raster() dat %&gt;% # cut the edges filter(x &gt; 1) %&gt;% filter(x &lt; max(x)) %&gt;% filter(y &gt; 1) %&gt;% filter(y &lt; max(y)) %&gt;% ggplot(., aes(x = x, y = y, fill = z)) + geom_raster() ggplot(dat, aes(x = x, y = y, fill = hab)) + geom_raster() ggplot(dat, aes(x = x, y = y, z = mu)) + geom_contour() tmp &lt;- rmvnorm(100, c(0, 0), diag(2)) %&gt;% rbind(., rmvnorm(100, c(2, 4), diag(2))) %&gt;% as_tibble moge &lt;- expand.grid(seq(3,-3, length = 100), seq(3,-3, length = 100)) moge %&gt;% mutate(p = dmvnorm(moge, c(0, 0), diag(2))) %&gt;% ggplot(., aes(x = Var1, y = Var2, z = p)) + geom_contour() m &lt;- ggplot(tmp, aes(x = V1, y = V2)) + geom_point() # contour lines m + geom_density_2d() dat2 &lt;- dat %&gt;% # mutate(hab_dummy = ifelse(hab == &quot;valley&quot;, 0, 1)) %&gt;% mutate(trait = rnorm(nrow(.), mu, 0.3)) # based on z dat2 %&gt;% ggplot(., aes(x = hab, y = trait, col = hab)) + geom_violin() + geom_jitter(width = 0.2) Ridge sites have greater trait values (e.g., thick dense leaves to grow well in dry conditions) Is this because those traits are favored in ridge sites? Is this just because neighbors have similar trait values (spatial autocorrelation)? "]
]
